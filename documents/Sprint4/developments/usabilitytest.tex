As the settings component started coming together, we decided it was time to re-evaluate the user interface design we originally presented to the clients in the second sprint (this is described in \cref{sec:sprint2:firstmeeting,sec:sprint2:secondmeeting,sec:sprint2:conclusionmeetings}).

At this point \launcher is still a relatively simple application, and since time is always an issue, we decided on a relatively informal test and evaluation, along the lines of the \textit{Instant Data Analysis} (IDA) method. 

\subsection{The IDA Method}
IDA emphasizes one-day usability test and evaluation sessions, that are meant to be more cost-efficient than the traditional \textit{Video Data Analysis} method. In its defining article, \citet{idaArticle} describe how the method should reveal most of the problems also revealed through VDA, but in much less time. 

IDA prescribes three players: 
\begin{itemize}
	\item The \textit{test monitor} instructs and observes the test subject during the usability test.
	\item The \textit{data logger} observes the tests, and records events of interest.
	\item Following the actual test session, the \textit{facilitator} runs a brainstorming session with the test monitor and the data logger, where the observed problems are discussed listed and rated. 
\end{itemize}

IDA test sessions are based on the think-aloud technique, where the test monitor gives test subject a number tasks in the system under test. The test subject then tries to solve the task while explaining his or her thoughts along the way. This makes it easier for the players to identify problematic areas. The data logger observes the session, and takes notes based on his observations. The facilitator may or may not be present during the test session.

After the test session, the test monitor and the data logger meet with the facilitator for a brainstorming session. The observations are presented to the facilitator, who starts compiling a list of usability problems on a white-board. Aside from controlling the discussion, it is the facilitators job to create an organised list of distinct usability problems, by categorising related observations, and eliminate redundancy. \citet{idaArticle} sets the length of this session to one hour. 

Finally the facilitator compiles a systematic list of problems, with a short description of each.

\subsection{Test Sessions}
We conducted test sessions with four different subjects:
\begin{itemize}
	\item The first subject has been a client to the \giraf project since it was initiated in 2011, and has tried the various programs several times. She describes herself as ``an okay computer user'', with some experience from the iOS environment, but comparatively little experience with the Android environment. 
	\item The second subject is also a client to the \giraf project, but has little experience in using it, as she feels it has not yet been ready for use. She also describes herself as ``an okay computer user'', with a lot of experience using iOS devices, but little experience with Android. 
	\item The third subject is a school teacher not associated with the \giraf project, but related to one of the developers. She has only superficial knowledge of \giraf, but is very used to Android.
	\item The fourth subject, an optician, is also a relation of one of the developers. As with the third subject, she only knows the \giraf project superficially, but uses the Android devices daily.
\end{itemize}

\subsection{Results}
Results
